#### HOW IT WORKS RN ####
# - No Backpropagation: No gradient updates, just weight mutations.
# - Selection + Mutation: Top-performing networks pass their weights to offspring.
# - Performance Evolves: Accuracy increases over generations.

#### TODO ####
# - Add crossover (combine two parents).
# - Try different activations like ReLU.
# - Experiment with bigger networks (more layers/neurons).
# - Adjust mutation rate for faster evolution.